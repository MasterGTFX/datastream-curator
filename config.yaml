llm:
  provider: "openrouter"           # openrouter, openai
  api_key: "${OPENROUTER_API_KEY}" # Environment variable reference
  model: "anthropic/claude-3-sonnet"
  temperature: 0.1                 # 0.0 = deterministic, 1.0 = creative
  max_tokens: 4096                 # Maximum response length
  timeout: 30                      # Request timeout in seconds

processing:
  batch_size: 100                  # Items per batch
  max_concurrent_requests: 5       # Concurrent LLM requests
  retry_attempts: 3                # Retry failed requests
  retry_delay: 1.0                 # Base delay between retries

output:
  format: "markdown"               # Output format
  include_metadata: true           # Include processing metadata
  preserve_structure: true         # Maintain existing structure

# Logging configuration
logging:
  level: "INFO"                    # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Enhanced diff configuration
diff_chunk_strategy: "recursive"    # token, sentence, recursive, semantic, sdpm, late, code, neural, slumber
diff_chunk_size: 1000              # Target chunk size in characters
diff_chunk_overlap: 100            # Overlap between chunks in characters
diff_use_semantic: true            # Use semantic awareness for chunking
diff_preserve_structure: true      # Preserve document structure during diff
diff_min_confidence: 0.7           # Minimum confidence for applying operations (0.0-1.0)