llm:
  provider: "openrouter"           # openrouter, openai
  api_key: "${OPENROUTER_API_KEY}" # Environment variable reference
  model: "anthropic/claude-3-sonnet"
  temperature: 0.1                 # 0.0 = deterministic, 1.0 = creative
  max_tokens: 4096                 # Maximum response length
  timeout: 30                      # Request timeout in seconds

processing:
  batch_size: 100                  # Items per batch
  max_concurrent_requests: 5       # Concurrent LLM requests
  retry_attempts: 3                # Retry failed requests
  retry_delay: 1.0                 # Base delay between retries

output:
  format: "markdown"               # Output format
  include_metadata: true           # Include processing metadata
  preserve_structure: true         # Maintain existing structure

# Logging configuration
logging:
  level: "INFO"                    # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"